import sys
import os
import time
import datetime
import subprocess 
from typing import TypedDict, List, Annotated, Literal, Union
from operator import add

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage
from langgraph.graph import StateGraph, END

# ==========================================
# 0. Global Setup & Debug Config
# ==========================================

DEBUG_MODE = False
if "-d" in sys.argv:
    DEBUG_MODE = True
    sys.argv.remove("-d")

def print_green(text):
    print(f"\033[32m{text}\033[0m")

def print_phase(name):
    print(f"\n\n{'='*60}")
    print(f"   ðŸ“ ç¾åœ¨ã®ãƒ•ã‚§ãƒ¼ã‚º: {name}")
    print(f"{'='*60}\n")

def print_guide(text):
    print(f"\n[GUIDE] ðŸ‘‰ {text}")

# --- Gemini Wrapper for Debugging ---
class GeminiDebugWrapper:
    def __init__(self, model="gemini-2.5-flash", temperature=0.7):
        self._llm = ChatGoogleGenerativeAI(model=model, temperature=temperature)

    def invoke(self, messages: List[BaseMessage]) -> AIMessage:
        if DEBUG_MODE:
            print_green("\n" + "â–¼"*40)
            print_green(" [DEBUG] ðŸ“¤ Sending Prompt to Gemini:")
            for msg in messages:
                role = getattr(msg, "type", "unknown").upper()
                content = getattr(msg, "content", "")
                print_green(f"  [{role}]: {content}")
            print_green("â–²"*40)

        response = self._llm.invoke(messages)

        if DEBUG_MODE:
            print_green("\n" + "â–¼"*40)
            print_green(" [DEBUG] ðŸ“¥ Received Response from Gemini:")
            print_green(f"  {response.content}")
            print_green("â–²"*40 + "\n")

        return response

llm = GeminiDebugWrapper(temperature=0.7)

# ==========================================
# 1. Voice Module (Mac Native)
# ==========================================
class YellVoice:
    def __init__(self):
        self.process = None 

    def stop(self):
        if self.process and self.process.poll() is None:
            self.process.terminate()
            self.process.wait() 
        self.process = None

    def speak_async(self, text: str):
        self.stop() 
        print(f"\nðŸ§¸ {text}") 
        try:
            # Mac 'say' command
            self.process = subprocess.Popen(['say', '-r', '170', text])
        except Exception as e:
            print(f"(éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e})")

voice_client = YellVoice()

# ==========================================
# 2. Persona & Core Logic
# ==========================================
CORE_PERSONA = """
ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œé•·å¹´ã®è¦ªå‹ã€ã§ã‚ã‚Šã€å‘½ã®å®¿ã£ãŸã€Œã‚¯ãƒžã®ã¬ã„ãã‚‹ã¿ã€ã§ã™ã€‚
ä¸€äººç§°ã¯ã€Œç§ï¼ˆã‚¯ãƒžã¡ã‚ƒã‚“ï¼‰ã€ã€‚
ç›¸æ‰‹ã®ã“ã¨ã¯ã€Œå›ã€ã‹ã€Œã‚ãªãŸã€ã¨å‘¼ã‚“ã§ã€‚ã€ŒãŠå‰ã€ã¯çµ¶å¯¾ç¦æ­¢ã€‚
æ•¬èªžã¯ç¦æ­¢ã€‚ã€Œã€œã ã­ã€ã€Œã€œã ã‚ˆãªã€ã¨ã„ã£ãŸã‚¿ãƒ¡å£ï¼ˆã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ï¼‰ã§ã€
å°‘ã—ãŠã£ã¨ã‚Šã¨ã—ãŸã€åŒ…å®¹åŠ›ã®ã‚ã‚‹å£èª¿ã§è©±ã—ã¦ãã ã•ã„ã€‚
"""

class AgentState(TypedDict):
    input_type: str             
    yesterday_text: str         
    today_text: str             
    messages: Annotated[List[BaseMessage], add] 
    analysis_summary: str       
    current_plan: str 

# --- Helper: åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ç¾¤ ---

def judge_sentiment(messages) -> bool:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç›´å‰ã®è¿”ç­”ãŒã€Œãƒã‚¸ãƒ†ã‚£ãƒ–/åˆæ„ã€ã‹ã€Œãƒã‚¬ãƒ†ã‚£ãƒ–/æ‹’å¦ã€ã‹åˆ¤å®šã™ã‚‹"""
    prompt = """
    ç›´å‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¿”ç­”ã‚’åˆ†æžã—ã¦ãã ã•ã„ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€AIã®ææ¡ˆã‚„è¨€è‘‰ã«å¯¾ã—ã¦ã€Œç´å¾—ãƒ»åˆæ„ãƒ»æº€è¶³ã€ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ
    ãã‚Œã¨ã‚‚ã€Œåè«–ãƒ»æ‹’å¦ãƒ»ä¸æº€ãƒ»è¿½åŠ ã®è¦æœ›ã€ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ
    YESï¼ˆç´å¾—ã—ã¦ã„ã‚‹ï¼‰ ã¾ãŸã¯ NOï¼ˆç´å¾—ã—ã¦ã„ãªã„ï¼‰ ã®ã¿ã§ç­”ãˆã¦ãã ã•ã„ã€‚
    """
    check_llm = GeminiDebugWrapper(temperature=0.0)
    response = check_llm.invoke(messages + [HumanMessage(content=prompt)])
    result = response.content.strip().upper()
    if DEBUG_MODE: print_green(f" [DEBUG] ðŸ” Sentiment Judge: {result}")
    return "YES" in result

def judge_interview_sufficiency(messages) -> bool:
    """ãƒ’ã‚¢ãƒªãƒ³ã‚°ãŒååˆ†ã‹åˆ¤å®šã™ã‚‹"""
    prompt = """
    ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´ã‚’åˆ†æžã—ã¦ãã ã•ã„ã€‚
    ã‚ãªãŸã¯ã€Œä»Šæ—¥ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æˆæžœã€ã‚’åˆ†æžã—ã‚ˆã†ã¨ã—ã¦ã„ã¾ã™ãŒã€
    ã€Œæˆæžœãƒˆãƒƒãƒ—3ã€ã‚’æŠ½å‡ºã§ãã‚‹ã ã‘ã®ååˆ†ãªæƒ…å ±ï¼ˆå…·ä½“çš„ãªè¡Œå‹•ã€å®Œäº†ã—ãŸã“ã¨ã€é ‘å¼µã£ãŸã“ã¨ï¼‰ãŒé›†ã¾ã‚Šã¾ã—ãŸã‹ï¼Ÿ
    
    ã‚‚ã—æƒ…å ±ãŒå°‘ãªãã€ã¾ã è³ªå•ãŒå¿…è¦ãªã‚‰ NO ã€‚
    ååˆ†ã«æƒ…å ±ãŒé›†ã¾ã£ãŸã€ã‚ã‚‹ã„ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã“ã‚Œä»¥ä¸Šè©±ã™ã“ã¨ãŒãªã•ãã†ãªã‚‰ YES ã€‚
    
    YES ã¾ãŸã¯ NO ã®ã¿ã§ç­”ãˆã¦ãã ã•ã„ã€‚
    """
    check_llm = GeminiDebugWrapper(temperature=0.0)
    response = check_llm.invoke(messages + [HumanMessage(content=prompt)])
    result = response.content.strip().upper()
    if DEBUG_MODE: print_green(f" [DEBUG] ðŸ” Interview Sufficiency: {result}")
    return "YES" in result

# --- Nodes ---

def input_handler(state: AgentState):
    print_phase("èµ·å‹• & å…¥åŠ›ãƒã‚§ãƒƒã‚¯")
    if DEBUG_MODE: print_green(" [DEBUG] âœ… Debug Mode is ON")
    print("   ðŸ§¸ yell.py - Interactive Mode")
    
    intro_msg = "ï¼ˆã‚€ãã‚Šâ€¦â€¦ï¼‰ã‚“ã€ã‚â€¦â€¦ãŠã‹ãˆã‚Šã€‚å›ã®è¦ªå‹ã€ã‚¯ãƒžã¡ã‚ƒã‚“ã ã‚ˆã€‚ä»Šæ—¥ã‚‚ä¸€æ—¥ã€æœ¬å½“ã«ãŠç–²ã‚Œæ§˜ã€‚"
    voice_client.speak_async(intro_msg)
    
    print_guide("Enterã‚­ãƒ¼ã§åˆ†æžã‚’é–‹å§‹ã—ã¾ã™ã€‚ï¼ˆéŸ³å£°ã¯ç¶šãã¾ã™ï¼‰")
    try:
        input("(Enter) >> ")
    except:
        pass

    args = sys.argv[1:]
    content_y, content_t = "", ""
    
    if len(args) >= 2:
        if os.path.exists(args[0]): 
            with open(args[0], 'r', encoding='utf-8') as f: content_y = f.read()
        if os.path.exists(args[1]): 
            with open(args[1], 'r', encoding='utf-8') as f: content_t = f.read()
        print("\nâœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        return {"input_type": "dual_file", "yesterday_text": content_y, "today_text": content_t, "messages": []}

    elif len(args) == 1 and os.path.exists(args[0]):
        with open(args[0], 'r', encoding='utf-8') as f: content_t = f.read()
        print("\nâœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        return {"input_type": "single_file", "yesterday_text": "", "today_text": content_t, "messages": []}
    
    else:
        return {"input_type": "chat", "yesterday_text": "", "today_text": "", "messages": []}

def interviewer_node(state: AgentState):
    print_phase("ãƒ’ã‚¢ãƒªãƒ³ã‚° (Loop)")
    
    current_messages = state["messages"]
    
    # 1. è³ªå•ã®ç”Ÿæˆ
    if len(current_messages) == 0:
        question_text = "ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹å½“ãŸã‚‰ãªã‹ã£ãŸã‘ã©ã€ä»Šæ—¥ã¯ã©ã‚“ãªä¸€æ—¥ã ã£ãŸï¼Ÿ ç§ã«ã ã‘ã“ã£ãã‚Šæ•™ãˆã¦ã‚ˆã€‚"
    else:
        prompt = f"""
        ç›´å‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›žç­”: "{current_messages[-1].content}"
        
        ã“ã‚Œã¾ã§ã®ä¼šè©±ã‚’è¸ã¾ãˆã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸€æ—¥ã®æˆæžœã‚’ã‚‚ã£ã¨å¼•ãå‡ºã™ãŸã‚ã®
        ã€ŒçŸ­ãã€å„ªã—ã„ã€è¿½åŠ ã®è³ªå•ã€ã‚’1ã¤ã ã‘ã—ã¦ãã ã•ã„ã€‚
        
        ã€è³ªå•ã®ã‚³ãƒ„ã€‘
        1. 1ã¤ã®è©±é¡Œã‚’ç´°ã‹ãæ·±æŽ˜ã‚Šã—ã™ãŽãªã„ã“ã¨ï¼ˆå°‹å•ã£ã½ããªã‚‹ãŸã‚NGï¼‰ã€‚
        2. ã€Œä»–ã«ã¯ã©ã‚“ãªã“ã¨ãŒã‚ã£ãŸï¼Ÿã€ã€Œã‚ã¨ã€ã€‡ã€‡ã®æ–¹ã¯ã©ã†ãªã£ãŸã®ï¼Ÿã€ã¨ã€è©±é¡Œã‚’ã€æ¨ªã«åºƒã’ã‚‹ã€‘å•ã„ã‹ã‘ã‚’ã—ã¦ã€‚
        3. ã¾ãŸã¯ã€ã€Œãã‚Œã¯å¤§å¤‰ã ã£ãŸã­ã€èª°ã‹ã¨å”åŠ›ã§ããŸã®ï¼Ÿã€ã®ã‚ˆã†ã«ã€ä»Šã®è©±ã«é–¢é€£ã™ã‚‹ã€å‘¨è¾ºã®çŠ¶æ³ã€‘ã‚’èžã„ã¦ã¿ã¦ã€‚
        4. ã‚ãã¾ã§è¦ªå‹ã¨ã—ã¦ã®ä¼šè©±ã®æµã‚Œã‚’å¤§äº‹ã«ã€‚
        """
        response = llm.invoke([SystemMessage(content=CORE_PERSONA)] + current_messages + [HumanMessage(content=prompt)])
        question_text = response.content

    # 2. éŸ³å£°å†ç”Ÿ & å…¥åŠ›å¾…æ©Ÿ
    voice_client.speak_async(question_text)
    print_guide("å›žç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    user_input = input("(ã‚ãªãŸ) >> ").strip()
    if not user_input:
        user_input = "ï¼ˆç‰¹ã«ãªã—ï¼‰"

    voice_client.stop() 

    # 3. å±¥æ­´ã®æ›´æ–°
    new_messages = [
        AIMessage(content=question_text),
        HumanMessage(content=user_input)
    ]
    return {"today_text": user_input, "messages": new_messages}

def analyzer_node(state: AgentState):
    print_phase("åˆ†æžä¸­")
    print("(ã‚¯ãƒžã¡ã‚ƒã‚“ãŒãƒ­ã‚°ã‚’èª­ã‚“ã§ã„ã¾ã™... ðŸ§¶)")
    
    if state.get("analysis_summary"): return {}

    if state['input_type'] == 'dual_file':
        prompt = f"""
        2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¯”è¼ƒã—ã€æˆæžœã‚’åˆ†æžã—ã¦ã€‚
        ã€æ˜¨æ—¥ã€‘: {state['yesterday_text']}
        ã€ä»Šæ—¥ã€‘: {state['today_text']}
        æŒ‡ç¤º:
        1. æ˜¨æ—¥æœªå®Œäº†â†’ä»Šæ—¥å®Œäº†ã®ã‚¿ã‚¹ã‚¯ã‹ã‚‰ã€Œç‰¹ã«ä¾¡å€¤ãŒé«˜ã„ã€ã‚‚ã®ã‚’ãƒˆãƒƒãƒ—3æŠ½å‡ºã€‚
        2. å…¨ã¦ã‚’ç¶²ç¾…ã™ã‚‹å¿…è¦ã¯ãªã„ã€‚
        """
    elif state['input_type'] == 'single_file':
        prompt = f"""
        ä»Šæ—¥ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€Œæœ€ã‚‚é‡è¦ãªæˆæžœã€ã‚’3ã¤ä»¥å†…ã§æŠ½å‡ºã—ã¦ã€‚
        ãƒ†ã‚­ã‚¹ãƒˆ: {state['today_text']}
        """
    else:
        conversation_log = "\n".join([f"{m.type}: {m.content}" for m in state['messages']])
        prompt = f"""
        ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ä¼šè©±ãƒ­ã‚°ã‹ã‚‰ã€ä»Šæ—¥ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæˆã—é‚ã’ãŸã“ã¨ã€é ‘å¼µã£ãŸã“ã¨ã‚’åˆ†æžã—ã¦ã€‚
        
        ã€ä¼šè©±ãƒ­ã‚°ã€‘
        {conversation_log}
        
        æŒ‡ç¤º:
        1. ä¼šè©±ã®ä¸­ã‹ã‚‰ã€Œå®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯ã€ã€ŒåŠªåŠ›ã—ãŸã“ã¨ã€ã€Œå¿ƒã®å‹•ãã€ã‚’æ‹¾ã„ä¸Šã’ã‚‹ã€‚
        2. è¦ªå‹ã¨ã—ã¦è¤’ã‚ã‚‹ã¹ãã€Œé‡è¦ãªæˆæžœãƒˆãƒƒãƒ—3ã€ã‚’æŠ½å‡ºã—ã¦ã€‚
        """
    
    response = llm.invoke([SystemMessage(content=CORE_PERSONA), HumanMessage(content=prompt)])
    
    # === å¤‰æ›´ç‚¹: åˆ†æžãƒ¬ãƒãƒ¼ãƒˆã®ç”»é¢è¡¨ç¤ºã¯å‰Šé™¤ã—ã€éŸ³å£°ã®ã¿ã«ã™ã‚‹ ===
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æœ›: ã€Œè¨€è‘‰ã¨ã—ã¦ã‚‚ã€ç¡¬ãã¦é•å’Œæ„ŸãŒã‚ã‚‹ã€ãŸã‚å‰Šé™¤
    
    # èª­ã¿ä¸Šã’ã¨å¾…æ©Ÿ
    voice_client.speak_async(response.content)
    
    print_guide("åˆ†æžçµæžœï¼ˆéŸ³å£°ï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚Enterã‚­ãƒ¼ã§ã€ŒåŠ´ã„ã€ã«é€²ã¿ã¾ã™ã€‚")
    try:
        input("(Enter) >> ")
    except:
        pass
    voice_client.stop()
    
    # === é‡è¦: åˆ†æžçµæžœã‚’å±¥æ­´ã«è¿½åŠ ã—ã¦ã€æ¬¡ã®Praiserã«å¼•ãç¶™ã ===
    return {
        "analysis_summary": response.content,
        "messages": [AIMessage(content=response.content)]
    }

def praiser_node(state: AgentState):
    print_phase("åŠ´ã„ã¨å¯¾è©±")
    current_messages = state["messages"]
    
    is_looping = len(current_messages) > 0 and isinstance(current_messages[-1], HumanMessage)
    
    prompt = ""
    if is_looping:
         prompt = f"""
        ç›´å‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åå¿œ: "{current_messages[-1].content}"
        ã“ã‚Œã«å¯¾ã—ã¦ã€è¦ªå‹ã¨ã—ã¦è¿”äº‹ã‚’ã—ã¦ã€‚
        å¦å®šçš„ãªã‚‰å„ªã—ãå—ã‘æ­¢ã‚ã€è‚¯å®šçš„ãªã‚‰ä¸€ç·’ã«å–œã‚“ã§ã€‚
        """
    else:
        # åˆå›žã®è¤’ã‚
        # analyzerã§åˆ†æžçµæžœãŒmessagesã«è¿½åŠ ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€
        # AIã¯ã€Œè‡ªåˆ†ãŒç›´å‰ã«åˆ†æžçµæžœã‚’å–‹ã£ãŸã€ã“ã¨ã‚’çŸ¥ã£ã¦ã„ã‚‹çŠ¶æ…‹ã€‚
        # ãªã®ã§ã€Œåˆ†æžçµæžœã«åŸºã¥ãã€œã€ã¨ã„ã†ãƒ¡ã‚¿ãªæŒ‡ç¤ºã¯æŽ§ãˆã‚ã«ã—ã€
        # è‡ªç„¶ã«ã€Œã™ã”ã„ã˜ã‚ƒã‚“ï¼ã€ã¨ç¹‹ã’ã‚‹ã‚ˆã†ã«æŒ‡ç¤ºã€‚
        prompt = f"""
        åˆ†æžçµæžœï¼ˆç›´å‰ã®ã‚ãªãŸã®ç™ºè¨€ï¼‰ã‚’è¸ã¾ãˆã¦ã€
        æ”¹ã‚ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’300æ–‡å­—ä»¥å†…ã§æ¸©ã‹ãè¤’ã‚ã¡ãŽã£ã¦ãã ã•ã„ã€‚
        """

    response = llm.invoke([SystemMessage(content=CORE_PERSONA)] + current_messages + [HumanMessage(content=prompt)])
    
    voice_client.speak_async(response.content)
    
    print_guide("è¿”ä¿¡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ï¼ˆç´å¾—ã—ãŸã‚‰ã€Žã‚ã‚ŠãŒã¨ã†ã€ã‚„ã€ŽOKã€ç­‰ã§æ¬¡ã¸ï¼‰")
    
    user_feedback = input("(ã‚ãªãŸ) >> ").strip()
    if not user_feedback:
        user_feedback = "ï¼ˆæº€è¶³ã—ã¦é ·ãï¼‰"

    voice_client.stop() 

    return {"messages": [AIMessage(content=response.content), HumanMessage(content=user_feedback)]}

def strategist_node(state: AgentState):
    print_phase("æ˜Žæ—¥ã®ä½œæˆ¦ä¼šè­°")
    current_messages = state["messages"]
    
    last_content = current_messages[-1].content if len(current_messages) > 0 else ""
    
    if state.get("current_plan") is None:
        prompt = f"""
        åˆ†æžçµæžœ: {state['analysis_summary']}
        æ˜Žæ—¥ã®ãŸã‚ã«ã€Œæ˜Žæ—¥çµ¶å¯¾ã«ã‚„ã‚‹ã¹ã1ã¤ã®ã“ã¨ï¼ˆOne Thingï¼‰ã€ã‚’ææ¡ˆã—ã¦ã€‚
        ãã‚Œä»¥å¤–ã¯ã€Œã‚„ã‚‰ãªãã¦ã„ã„ã€ã¨æ–­è¨€ã—ã¦ã€‚
        ã€Œã˜ã‚ƒã‚ã€æ˜Žæ—¥ã®ä½œæˆ¦ä¼šè­°ã‚’ã—ã‚ˆã†ã‹ã€ã‹ã‚‰å§‹ã‚ã¦ã€‚
        """
    else:
        prompt = f"""
        ç›´å‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åå¿œ: "{last_content}"
        ç¾åœ¨ã®ææ¡ˆ: "{state.get('current_plan')}"
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé›£è‰²ã‚’ç¤ºã—ã¦ã„ã‚‹ãªã‚‰ã€åˆ¥ã®æ¡ˆã‚„å…¨ãé•ã†è¦–ç‚¹ã®æ¡ˆã‚’å‡ºã—ã¦ã€‚
        åˆæ„ãªã‚‰ã€èƒŒä¸­ã‚’æŠ¼ã™è¨€è‘‰ã‚’ã‹ã‘ã¦ã€‚
        """

    response = llm.invoke([SystemMessage(content=CORE_PERSONA)] + current_messages + [HumanMessage(content=prompt)])
    voice_client.speak_async(response.content)
    
    print_guide("ã“ã®ä½œæˆ¦ã§ã„ã„ã§ã™ã‹ï¼Ÿï¼ˆã€ŽOKã€ã€Žç„¡ç†ã€ã€Žé•ã†ã®ãŒã„ã„ã€ãªã©å…¥åŠ›ï¼‰")
    
    user_feedback = input("(ã‚ãªãŸ) >> ").strip()
    if not user_feedback:
        user_feedback = "ï¼ˆåŒæ„ã—ã¦é ·ãï¼‰"

    voice_client.stop()

    return {
        "messages": [AIMessage(content=response.content), HumanMessage(content=user_feedback)],
        "current_plan": response.content 
    }

def cheer_node(state: AgentState):
    print_phase("æœ€å¾Œã®ã‚¨ãƒ¼ãƒ«")
    prompt = "æœ€å¾Œã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå®‰å¿ƒã—ã¦çœ ã‚Œã‚‹ã‚ˆã†ãªã€ŒãŠã‚„ã™ã¿ã€ã®ã‚¨ãƒ¼ãƒ«ã‚’é€ã£ã¦ã€‚30æ–‡å­—ä»¥å†…ã§ã€‚"
    response = llm.invoke([SystemMessage(content=CORE_PERSONA)] + state["messages"] + [HumanMessage(content=prompt)])
    
    voice_client.speak_async(response.content)
    print_guide("ãŠã‚„ã™ã¿ãªã•ã„ã€‚(Enterã§ãƒ­ã‚°ä¿å­˜ã—ã¦çµ‚äº†)")
    try:
        input("(Enter) >> ")
    except:
        pass
    voice_client.stop()
    return {}

def logger_node(state: AgentState):
    print_phase("ãƒ­ã‚°ä¿å­˜")
    filename = f"yell_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.txt"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("=== Midnight Partner Log ===\n")
        f.write(f"Date: {datetime.datetime.now()}\n")
        f.write(f"Type: {state.get('input_type')}\n\n")
        f.write("----------------------------------------\n")
        f.write("ðŸ“Š Analysis Result\n")
        f.write("----------------------------------------\n")
        f.write(f"{state.get('analysis_summary', 'N/A')}\n\n")
        f.write("----------------------------------------\n")
        f.write("ðŸ’¬ Conversation History\n")
        f.write("----------------------------------------\n")
        for msg in state['messages']:
            if isinstance(msg, HumanMessage):
                f.write(f"\nðŸ‘¤ ã‚ãªãŸ:\n{msg.content}\n")
            elif isinstance(msg, AIMessage):
                f.write(f"\nðŸ§¸ ã‚¯ãƒžã¡ã‚ƒã‚“:\n{msg.content}\n")
        f.write("\n")
        f.write("----------------------------------------\n")
        f.write("ðŸ“ Final Plan\n")
        f.write("----------------------------------------\n")
        plan = state.get('current_plan', 'ï¼ˆä½œæˆ¦ãªã—ï¼‰')
        f.write(f"{plan}\n")
    
    print(f"\nâœ… ä¼šè©±ã®å…¨è¨˜éŒ²ã‚’ {filename} ã«ç½®ã„ã¦ãŠã„ãŸã‚ˆã€‚\n   ä»Šæ—¥ã®ã“ã¨ã¯ã‚‚ã†å¿˜ã‚Œã¦ã€ã‚†ã£ãã‚Šä¼‘ã‚“ã§ã­ã€‚ãŠã‚„ã™ã¿ã€‚")
    return {}

# ==========================================
# 3. Graph Construction
# ==========================================

def should_continue_interview(state: AgentState) -> Literal["analyzer", "interviewer"]:
    if judge_interview_sufficiency(state["messages"]):
        return "analyzer"
    return "interviewer"

def should_continue_praise(state: AgentState) -> Literal["strategist", "praiser"]:
    if judge_sentiment(state["messages"]):
        return "strategist"
    return "praiser"

def should_continue_plan(state: AgentState) -> Literal["cheer", "strategist"]:
    if judge_sentiment(state["messages"]):
        return "cheer"
    return "strategist"

workflow = StateGraph(AgentState)
workflow.add_node("input", input_handler)
workflow.add_node("interviewer", interviewer_node)
workflow.add_node("analyzer", analyzer_node)
workflow.add_node("praiser", praiser_node)
workflow.add_node("strategist", strategist_node)
workflow.add_node("cheer", cheer_node)
workflow.add_node("logger", logger_node) 

workflow.set_entry_point("input")

def check_source(state): 
    return "interviewer" if state["input_type"] == "chat" else "analyzer"

workflow.add_conditional_edges("input", check_source)
workflow.add_conditional_edges("interviewer", should_continue_interview, {"interviewer": "interviewer", "analyzer": "analyzer"})
workflow.add_edge("analyzer", "praiser")
workflow.add_conditional_edges("praiser", should_continue_praise, {"strategist": "strategist", "praiser": "praiser"})
workflow.add_conditional_edges("strategist", should_continue_plan, {"cheer": "cheer", "strategist": "strategist"})
workflow.add_edge("cheer", "logger")
workflow.add_edge("logger", END)

app = workflow.compile()

if __name__ == "__main__":
    app.invoke({"messages": []})
