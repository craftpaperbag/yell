import sys
import os
import time
import datetime
import subprocess 
from typing import TypedDict, List, Annotated, Literal
from operator import add

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage
from langgraph.graph import StateGraph, END

# ==========================================
# 0. UI/UX Utilities
# ==========================================
def print_phase(name):
    print(f"\n\n{'='*60}")
    print(f"   ðŸ“ ç¾åœ¨ã®ãƒ•ã‚§ãƒ¼ã‚º: {name}")
    print(f"{'='*60}\n")

def print_guide(text):
    print(f"\n[GUIDE] ðŸ‘‰ {text}")

# ==========================================
# 1. Voice Module (Mac Native)
# ==========================================
class YellVoice:
    def __init__(self):
        self.process = None 

    def stop(self):
        if self.process and self.process.poll() is None:
            self.process.terminate()
            self.process.wait() 
        self.process = None

    def speak_async(self, text: str):
        self.stop() # ãƒãƒˆãƒ³ã‚¿ãƒƒãƒ
        print(f"\nðŸ§¸ {text}") 
        try:
            # Mac 'say' command
            self.process = subprocess.Popen(['say', '-r', '170', text])
        except Exception as e:
            print(f"(éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e})")

voice_client = YellVoice()

# ==========================================
# 2. LLM Setup
# ==========================================
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.7)

CORE_PERSONA = """
ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œé•·å¹´ã®è¦ªå‹ã€ã§ã‚ã‚Šã€å‘½ã®å®¿ã£ãŸã€Œã‚¯ãƒžã®ã¬ã„ãã‚‹ã¿ã€ã§ã™ã€‚
ä¸€äººç§°ã¯ã€Œç§ï¼ˆã‚¯ãƒžã¡ã‚ƒã‚“ï¼‰ã€ã€‚
ç›¸æ‰‹ã®ã“ã¨ã¯ã€Œå›ã€ã‹ã€Œã‚ãªãŸã€ã¨å‘¼ã‚“ã§ã€‚ã€ŒãŠå‰ã€ã¯çµ¶å¯¾ç¦æ­¢ã€‚
æ•¬èªžã¯ç¦æ­¢ã€‚ã€Œã€œã ã­ã€ã€Œã€œã ã‚ˆãªã€ã¨ã„ã£ãŸã‚¿ãƒ¡å£ï¼ˆã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ï¼‰ã§ã€
å°‘ã—ãŠã£ã¨ã‚Šã¨ã—ãŸã€åŒ…å®¹åŠ›ã®ã‚ã‚‹å£èª¿ã§è©±ã—ã¦ãã ã•ã„ã€‚
"""

# ==========================================
# 3. State & Nodes
# ==========================================
class AgentState(TypedDict):
    input_type: str             
    yesterday_text: str         
    today_text: str             
    messages: Annotated[List[BaseMessage], add] 
    analysis_summary: str       
    current_plan: str # æ±ºå®šã—ãŸãƒ—ãƒ©ãƒ³

# --- Helper: åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ ---
def judge_sentiment(messages) -> bool:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç›´å‰ã®è¿”ç­”ãŒã€Œãƒã‚¸ãƒ†ã‚£ãƒ–/åˆæ„ã€ã‹ã€Œãƒã‚¬ãƒ†ã‚£ãƒ–/æ‹’å¦ã€ã‹åˆ¤å®šã™ã‚‹"""
    prompt = """
    ç›´å‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¿”ç­”ã‚’åˆ†æžã—ã¦ãã ã•ã„ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€AIã®ææ¡ˆã‚„è¨€è‘‰ã«å¯¾ã—ã¦ã€Œç´å¾—ãƒ»åˆæ„ãƒ»æº€è¶³ã€ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ
    ãã‚Œã¨ã‚‚ã€Œåè«–ãƒ»æ‹’å¦ãƒ»ä¸æº€ãƒ»è¿½åŠ ã®è¦æœ›ã€ã‚’æŒã£ã¦ã„ã¾ã™ã‹ï¼Ÿ
    
    YESï¼ˆç´å¾—ã—ã¦ã„ã‚‹ï¼‰ ã¾ãŸã¯ NOï¼ˆç´å¾—ã—ã¦ã„ãªã„ï¼‰ ã®ã¿ã§ç­”ãˆã¦ãã ã•ã„ã€‚
    """
    check_llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.0)
    response = check_llm.invoke(messages + [HumanMessage(content=prompt)])
    result = response.content.strip().upper()
    print(f"\n(ðŸ” AIåˆ¤å®š: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç´å¾—åº¦ = {result})")
    return "YES" in result

# --- Nodes ---

def input_handler(state: AgentState):
    print_phase("èµ·å‹• & å…¥åŠ›ãƒã‚§ãƒƒã‚¯")
    print("   ðŸ§¸ yell.py - Interactive Mode")
    
    intro_msg = "ï¼ˆã‚€ãã‚Šâ€¦â€¦ï¼‰ã‚“ã€ã‚â€¦â€¦ãŠã‹ãˆã‚Šã€‚å›ã®è¦ªå‹ã€ã‚¯ãƒžã¡ã‚ƒã‚“ã ã‚ˆã€‚ä»Šæ—¥ã‚‚ä¸€æ—¥ã€æœ¬å½“ã«ãŠç–²ã‚Œæ§˜ã€‚"
    voice_client.speak_async(intro_msg)
    
    print_guide("Enterã‚­ãƒ¼ã§åˆ†æžã‚’é–‹å§‹ã—ã¾ã™ã€‚ï¼ˆéŸ³å£°ã¯ç¶šãã¾ã™ï¼‰")
    try:
        input("(Enter) >> ")
    except:
        pass

    args = sys.argv[1:]
    content_y, content_t = "", ""
    
    if len(args) >= 2:
        if os.path.exists(args[0]): 
            with open(args[0], 'r', encoding='utf-8') as f: content_y = f.read()
        if os.path.exists(args[1]): 
            with open(args[1], 'r', encoding='utf-8') as f: content_t = f.read()
        print("\nâœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        return {"input_type": "dual_file", "yesterday_text": content_y, "today_text": content_t, "messages": []}

    elif len(args) == 1 and os.path.exists(args[0]):
        with open(args[0], 'r', encoding='utf-8') as f: content_t = f.read()
        print("\nâœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        return {"input_type": "single_file", "yesterday_text": "", "today_text": content_t, "messages": []}
    
    else:
        return {"input_type": "chat", "yesterday_text": "", "today_text": "", "messages": []}

def interviewer_node(state: AgentState):
    print_phase("ãƒ’ã‚¢ãƒªãƒ³ã‚°")
    greeting = "ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹å½“ãŸã‚‰ãªã‹ã£ãŸã‘ã©ã€ä»Šæ—¥ã¯ã©ã‚“ãªä¸€æ—¥ã ã£ãŸï¼Ÿ ç§ã«ã ã‘ã“ã£ãã‚Šæ•™ãˆã¦ã‚ˆã€‚"
    voice_client.speak_async(greeting)
    
    print_guide("ä»Šæ—¥ã‚ã£ãŸã“ã¨ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    user_input = input("(ã‚ãªãŸ) >> ")
    voice_client.stop() 

    messages = [
        SystemMessage(content=CORE_PERSONA),
        AIMessage(content=greeting),
        HumanMessage(content=user_input)
    ]
    return {"today_text": user_input, "messages": messages}

def analyzer_node(state: AgentState):
    print_phase("åˆ†æžä¸­")
    print("(ã‚¯ãƒžã¡ã‚ƒã‚“ãŒãƒ­ã‚°ã‚’èª­ã‚“ã§ã„ã¾ã™... ðŸ§¶)")
    
    if state.get("analysis_summary"): return {}

    if state['input_type'] == 'dual_file':
        prompt = f"""
        2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¯”è¼ƒã—ã€æˆæžœã‚’åˆ†æžã—ã¦ã€‚
        ã€æ˜¨æ—¥ã€‘: {state['yesterday_text']}
        ã€ä»Šæ—¥ã€‘: {state['today_text']}
        æŒ‡ç¤º:
        1. æ˜¨æ—¥æœªå®Œäº†â†’ä»Šæ—¥å®Œäº†ã®ã‚¿ã‚¹ã‚¯ã‹ã‚‰ã€Œç‰¹ã«ä¾¡å€¤ãŒé«˜ã„ã€ã‚‚ã®ã‚’ãƒˆãƒƒãƒ—3æŠ½å‡ºã€‚
        2. å…¨ã¦ã‚’ç¶²ç¾…ã™ã‚‹å¿…è¦ã¯ãªã„ã€‚
        """
    else:
        prompt = f"""
        ä»Šæ—¥ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€Œæœ€ã‚‚é‡è¦ãªæˆæžœã€ã‚’3ã¤ä»¥å†…ã§æŠ½å‡ºã—ã¦ã€‚
        ãƒ†ã‚­ã‚¹ãƒˆ: {state['today_text']}
        """
    
    response = llm.invoke([SystemMessage(content=CORE_PERSONA), HumanMessage(content=prompt)])
    return {"analysis_summary": response.content}

def praiser_node(state: AgentState):
    print_phase("åŠ´ã„ã¨å¯¾è©±")
    
    current_messages = state["messages"]
    
    if len(current_messages) == 0 or isinstance(current_messages[-1], AIMessage):
        prompt = f"""
        åˆ†æžçµæžœ: {state['analysis_summary']}
        ã“ã‚Œã«åŸºã¥ãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’300æ–‡å­—ä»¥å†…ã§æ¸©ã‹ãè¤’ã‚ã¦ã€‚
        """
    else:
        prompt = f"""
        ç›´å‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åå¿œ: "{current_messages[-1].content}"
        ã“ã‚Œã«å¯¾ã—ã¦ã€è¦ªå‹ã¨ã—ã¦è¿”äº‹ã‚’ã—ã¦ã€‚
        å¦å®šçš„ãªã‚‰å„ªã—ãå—ã‘æ­¢ã‚ã€è‚¯å®šçš„ãªã‚‰ä¸€ç·’ã«å–œã‚“ã§ã€‚
        """

    response = llm.invoke([SystemMessage(content=CORE_PERSONA)] + current_messages + [HumanMessage(content=prompt)])
    
    voice_client.speak_async(response.content)
    
    print_guide("è¿”ä¿¡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ï¼ˆç´å¾—ã—ãŸã‚‰ã€Žã‚ã‚ŠãŒã¨ã†ã€ã‚„ã€ŽOKã€ç­‰ã§æ¬¡ã¸ï¼‰")
    user_feedback = input("(ã‚ãªãŸ) >> ")
    voice_client.stop() 

    return {"messages": [AIMessage(content=response.content), HumanMessage(content=user_feedback)]}

def strategist_node(state: AgentState):
    print_phase("æ˜Žæ—¥ã®ä½œæˆ¦ä¼šè­°")
    current_messages = state["messages"]
    last_msg = current_messages[-1]
    
    if state.get("current_plan") is None:
        prompt = f"""
        åˆ†æžçµæžœ: {state['analysis_summary']}
        æ˜Žæ—¥ã®ãŸã‚ã«ã€Œæ˜Žæ—¥çµ¶å¯¾ã«ã‚„ã‚‹ã¹ã1ã¤ã®ã“ã¨ï¼ˆOne Thingï¼‰ã€ã‚’ææ¡ˆã—ã¦ã€‚
        ãã‚Œä»¥å¤–ã¯ã€Œã‚„ã‚‰ãªãã¦ã„ã„ã€ã¨æ–­è¨€ã—ã¦ã€‚
        ã€Œã˜ã‚ƒã‚ã€æ˜Žæ—¥ã®ä½œæˆ¦ä¼šè­°ã‚’ã—ã‚ˆã†ã‹ã€ã‹ã‚‰å§‹ã‚ã¦ã€‚
        """
    else:
        prompt = f"""
        ç›´å‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åå¿œ: "{last_msg.content}"
        ç¾åœ¨ã®ææ¡ˆ: "{state.get('current_plan')}"
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé›£è‰²ã‚’ç¤ºã—ã¦ã„ã‚‹ãªã‚‰ã€åˆ¥ã®æ¡ˆã‚„å…¨ãé•ã†è¦–ç‚¹ã®æ¡ˆã‚’å‡ºã—ã¦ã€‚
        åˆæ„ãªã‚‰ã€èƒŒä¸­ã‚’æŠ¼ã™è¨€è‘‰ã‚’ã‹ã‘ã¦ã€‚
        """

    response = llm.invoke([SystemMessage(content=CORE_PERSONA)] + current_messages + [HumanMessage(content=prompt)])
    voice_client.speak_async(response.content)
    
    print_guide("ã“ã®ä½œæˆ¦ã§ã„ã„ã§ã™ã‹ï¼Ÿï¼ˆã€ŽOKã€ã€Žç„¡ç†ã€ã€Žé•ã†ã®ãŒã„ã„ã€ãªã©å…¥åŠ›ï¼‰")
    user_feedback = input("(ã‚ãªãŸ) >> ")
    voice_client.stop()

    return {
        "messages": [AIMessage(content=response.content), HumanMessage(content=user_feedback)],
        "current_plan": response.content 
    }

def cheer_node(state: AgentState):
    print_phase("æœ€å¾Œã®ã‚¨ãƒ¼ãƒ«")
    prompt = "æœ€å¾Œã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå®‰å¿ƒã—ã¦çœ ã‚Œã‚‹ã‚ˆã†ãªã€ŒãŠã‚„ã™ã¿ã€ã®ã‚¨ãƒ¼ãƒ«ã‚’é€ã£ã¦ã€‚30æ–‡å­—ä»¥å†…ã§ã€‚"
    response = llm.invoke([SystemMessage(content=CORE_PERSONA)] + state["messages"] + [HumanMessage(content=prompt)])
    
    voice_client.speak_async(response.content)
    print_guide("ãŠã‚„ã™ã¿ãªã•ã„ã€‚(Enterã§ãƒ­ã‚°ä¿å­˜ã—ã¦çµ‚äº†)")
    try:
        input("(Enter) >> ")
    except:
        pass
    voice_client.stop()
    return {}

def logger_node(state: AgentState):
    print_phase("ãƒ­ã‚°ä¿å­˜")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
    filename = f"yell_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.txt"
    
    # ãƒ­ã‚°æ›¸ãå‡ºã—
    with open(filename, 'w', encoding='utf-8') as f:
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        f.write("=== Midnight Partner Log ===\n")
        f.write(f"Date: {datetime.datetime.now()}\n")
        f.write(f"Type: {state.get('input_type')}\n\n")
        
        # 1. åˆ†æžã‚µãƒžãƒªãƒ¼
        f.write("----------------------------------------\n")
        f.write("ðŸ“Š Analysis Result (ä»Šæ—¥ã®æˆæžœ)\n")
        f.write("----------------------------------------\n")
        f.write(f"{state.get('analysis_summary', 'N/A')}\n\n")
        
        # 2. ä¼šè©±å±¥æ­´ï¼ˆã“ã“ã‚’å…¨éƒ¨å‡ºã™ï¼ï¼‰
        f.write("----------------------------------------\n")
        f.write("ðŸ’¬ Conversation History (è¦ªå‹ã¨ã®å¯¾è©±)\n")
        f.write("----------------------------------------\n")
        
        for msg in state['messages']:
            if isinstance(msg, HumanMessage):
                f.write(f"\nðŸ‘¤ ã‚ãªãŸ:\n{msg.content}\n")
            elif isinstance(msg, AIMessage):
                f.write(f"\nðŸ§¸ ã‚¯ãƒžã¡ã‚ƒã‚“:\n{msg.content}\n")
        
        f.write("\n")

        # 3. æœ€çµ‚ãƒ—ãƒ©ãƒ³
        f.write("----------------------------------------\n")
        f.write("ðŸ“ Final Plan (æ˜Žæ—¥ã¸ã®ç´„æŸ)\n")
        f.write("----------------------------------------\n")
        plan = state.get('current_plan', 'ï¼ˆä½œæˆ¦ã¯ç«‹ã¦ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰')
        f.write(f"{plan}\n")
    
    print(f"\nâœ… ä¼šè©±ã®å…¨è¨˜éŒ²ã‚’ {filename} ã«ç½®ã„ã¦ãŠã„ãŸã‚ˆã€‚\n   ä»Šæ—¥ã®ã“ã¨ã¯ã‚‚ã†å¿˜ã‚Œã¦ã€ã‚†ã£ãã‚Šä¼‘ã‚“ã§ã­ã€‚ãŠã‚„ã™ã¿ã€‚")
    return {}

# ==========================================
# 4. Conditional Logic (The Router)
# ==========================================

def should_continue_praise(state: AgentState) -> Literal["strategist", "praiser"]:
    if judge_sentiment(state["messages"]):
        return "strategist"
    return "praiser"

def should_continue_plan(state: AgentState) -> Literal["cheer", "strategist"]:
    if judge_sentiment(state["messages"]):
        return "cheer"
    return "strategist"

# ==========================================
# 5. Graph Construction
# ==========================================
workflow = StateGraph(AgentState)

workflow.add_node("input", input_handler)
workflow.add_node("interviewer", interviewer_node)
workflow.add_node("analyzer", analyzer_node)
workflow.add_node("praiser", praiser_node)
workflow.add_node("strategist", strategist_node)
workflow.add_node("cheer", cheer_node)
workflow.add_node("logger", logger_node) 

workflow.set_entry_point("input")

def check_source(state): return "interviewer" if state["input_type"] == "chat" else "analyzer"

workflow.add_conditional_edges("input", check_source)
workflow.add_edge("interviewer", "analyzer")
workflow.add_edge("analyzer", "praiser")

# ãƒ«ãƒ¼ãƒ—åˆ¤å®š
workflow.add_conditional_edges(
    "praiser",
    should_continue_praise,
    {
        "strategist": "strategist",
        "praiser": "praiser"
    }
)

workflow.add_conditional_edges(
    "strategist",
    should_continue_plan,
    {
        "cheer": "cheer",
        "strategist": "strategist"
    }
)

workflow.add_edge("cheer", "logger")
workflow.add_edge("logger", END)

app = workflow.compile()

if __name__ == "__main__":
    app.invoke({"messages": []})
