import sys
import os
import time
import datetime
import pyttsx3
import threading
from typing import TypedDict, List, Annotated
from operator import add

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage
from langgraph.graph import StateGraph, END

# ==========================================
# 0. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ (UI/UX)
# ==========================================
def print_phase(name):
    """ç¾åœ¨ã®ãƒãƒ¼ãƒ‰ï¼ˆãƒ•ã‚§ãƒ¼ã‚ºï¼‰ã‚’ç›®ç«‹ãŸã›ã‚‹"""
    print(f"\n\n{'='*60}")
    print(f"   ğŸ“ ç¾åœ¨ã®ãƒ•ã‚§ãƒ¼ã‚º: {name}")
    print(f"{'='*60}\n")

def print_guide(text):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å…¥åŠ›ã‚¬ã‚¤ãƒ‰ã‚’è¡¨ç¤º"""
    print(f"\n[GUIDE] ğŸ‘‰ {text}")

# ==========================================
# 1. éŸ³å£° & æ¼”å‡ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (Voice & UX)
# ==========================================
class YellVoice:
    def __init__(self):
        self.current_engine = None
        self.speaking_thread = None 
        self.lock = threading.Lock() 

    def _speak_thread_func(self, text):
        try:
            engine = pyttsx3.init()
            voices = engine.getProperty('voices')
            for voice in voices:
                if "jp" in voice.id.lower() or "japan" in voice.name.lower():
                    engine.setProperty('voice', voice.id)
                    break
            engine.setProperty('rate', 160) 
            engine.setProperty('volume', 1.0)
            
            self.current_engine = engine
            engine.say(text)
            engine.runAndWait()
        except Exception:
            pass
        finally:
            self.current_engine = None

    def stop(self):
        if self.current_engine:
            try:
                self.current_engine.stop()
            except:
                pass
        if self.speaking_thread and self.speaking_thread.is_alive():
            self.speaking_thread.join() 

    def speak_async(self, text: str):
        with self.lock:
            self.stop()
            time.sleep(0.3)
            print(f"\nğŸ§¸ {text}") 
            t = threading.Thread(target=self._speak_thread_func, args=(text,))
            t.daemon = True 
            self.speaking_thread = t
            t.start()

voice_client = YellVoice()

# ==========================================
# 2. Gemini (LLM) ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
# ==========================================
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.7)

CORE_PERSONA = """
ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œé•·å¹´ã®è¦ªå‹ã€ã§ã‚ã‚Šã€å‘½ã®å®¿ã£ãŸã€Œã‚¯ãƒã®ã¬ã„ãã‚‹ã¿ã€ã§ã™ã€‚
ä¸€äººç§°ã¯ã€Œç§ï¼ˆã‚¯ãƒã¡ã‚ƒã‚“ï¼‰ã€ã€‚
ç›¸æ‰‹ã®ã“ã¨ã¯ã€Œå›ã€ã‹ã€Œã‚ãªãŸã€ã¨å‘¼ã‚“ã§ã€‚ã€ŒãŠå‰ã€ã¯çµ¶å¯¾ç¦æ­¢ã€‚
æ•¬èªã¯ç¦æ­¢ã€‚ã€Œã€œã ã­ã€ã€Œã€œã ã‚ˆãªã€ã¨ã„ã£ãŸã‚¿ãƒ¡å£ï¼ˆã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ï¼‰ã§ã€
å°‘ã—ãŠã£ã¨ã‚Šã¨ã—ãŸã€åŒ…å®¹åŠ›ã®ã‚ã‚‹å£èª¿ã§è©±ã—ã¦ãã ã•ã„ã€‚
"""

# ==========================================
# 3. State & Nodes
# ==========================================
class AgentState(TypedDict):
    input_type: str             
    yesterday_text: str         
    today_text: str             
    messages: Annotated[List[BaseMessage], add] 
    analysis_summary: str       
    plan_focus: str             

def input_handler(state: AgentState):
    """èµ·å‹•æ™‚ã®æ¼”å‡ºã¨å…¥åŠ›åˆ¤å®š"""
    print_phase("èµ·å‹• & å…¥åŠ›ãƒã‚§ãƒƒã‚¯ (Input Handler)")
    
    print("   ğŸ§¸ yell.py - Midnight Partner Demo")
    
    intro_msg = "ï¼ˆã‚€ãã‚Šâ€¦â€¦ï¼‰ã‚“ã€ã‚â€¦â€¦ãŠã‹ãˆã‚Šã€‚å›ã®è¦ªå‹ã€ã‚¯ãƒã¡ã‚ƒã‚“ã ã‚ˆã€‚ä»Šæ—¥ã‚‚ä¸€æ—¥ã€æœ¬å½“ã«ãŠç–²ã‚Œæ§˜ã€‚"
    voice_client.speak_async(intro_msg)
    
    print_guide("ã‚¯ãƒã¡ã‚ƒã‚“ãŒèµ·ãã¾ã—ãŸã€‚Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦åˆ†æã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚")
    try:
        input("(Enter) >> ")
    except:
        pass
    voice_client.stop()

    args = sys.argv[1:]
    
    if len(args) >= 2:
        path_yesterday = args[0]
        path_today = args[1]
        content_y = ""
        content_t = ""
        if os.path.exists(path_yesterday):
            with open(path_yesterday, 'r', encoding='utf-8') as f: content_y = f.read()
        if os.path.exists(path_today):
            with open(path_today, 'r', encoding='utf-8') as f: content_t = f.read()
        print("\nâœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: 2ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¯”è¼ƒã—ã¾ã™")
        return {"input_type": "dual_file", "yesterday_text": content_y, "today_text": content_t}

    elif len(args) == 1 and os.path.exists(args[0]):
        with open(args[0], 'r', encoding='utf-8') as f: content = f.read()
        print("\nâœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: 1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã¾ã™")
        return {"input_type": "single_file", "yesterday_text": "", "today_text": content}
    
    else:
        return {"input_type": "chat", "yesterday_text": "", "today_text": ""}

def interviewer_node(state: AgentState):
    print_phase("ãƒ’ã‚¢ãƒªãƒ³ã‚° (Interviewer)")
    voice_client.stop() 
    greeting = "ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹å½“ãŸã‚‰ãªã‹ã£ãŸã‘ã©ã€ä»Šæ—¥ã¯ã©ã‚“ãªä¸€æ—¥ã ã£ãŸï¼Ÿ ç§ã«ã ã‘ã“ã£ãã‚Šæ•™ãˆã¦ã‚ˆã€‚"
    voice_client.speak_async(greeting)
    
    print_guide("ä»Šæ—¥ã‚ã£ãŸã“ã¨ã‚’è‡ªç”±ã«å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆå…¥åŠ›å®Œäº†å¾Œã«Enterï¼‰")
    user_input = input("(ã‚ãªãŸ) >> ")
    voice_client.stop() 

    messages = [
        SystemMessage(content=CORE_PERSONA),
        AIMessage(content=greeting),
        HumanMessage(content=user_input)
    ]
    ack_msg = "ãã£ã‹ãã£ã‹â€¦â€¦ã€‚è©±ã—ã¦ãã‚Œã¦ã‚ã‚ŠãŒã¨ã†ã­ã€‚"
    voice_client.speak_async(ack_msg)
    time.sleep(1.5)
    return {"today_text": user_input, "messages": messages}

def analyzer_node(state: AgentState):
    print_phase("åˆ†æä¸­ (Analyzer)")
    voice_client.stop()
    print("(ã‚¯ãƒã¡ã‚ƒã‚“ãŒãƒ­ã‚°ã‚’èª­ã‚“ã§ã„ã¾ã™... ğŸ§¶)")
    
    if state['input_type'] == 'dual_file':
        prompt = f"""
        ä»¥ä¸‹ã®2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¯”è¼ƒã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æˆæœã‚’åˆ†æã—ã¦ã€‚
        ã€æ˜¨æ—¥ã®ãƒ¡ãƒ¢ï¼ˆäºˆå®šï¼‰ã€‘: {state['yesterday_text']}
        ã€ä»Šæ—¥ã®ãƒ¡ãƒ¢ï¼ˆçµæœï¼‰ã€‘: {state['today_text']}
        æŒ‡ç¤º:
        1. æ˜¨æ—¥ã¯æœªå®Œäº†ã ã£ãŸãŒã€ä»Šæ—¥å®Œäº†ã—ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã®ä¸­ã‹ã‚‰ã€ã€Œç‰¹ã«å¤§å¤‰ãã†ã€ã€Œä¾¡å€¤ãŒé«˜ã„ã€ã¨æ€ã‚ã‚Œã‚‹ã‚‚ã®ã‚’ã€ãƒˆãƒƒãƒ—3ã€‘ã ã‘æŠ½å‡ºã—ã¦ã€‚
        2. å…¨ã¦ã‚’ç¶²ç¾…ã™ã‚‹å¿…è¦ã¯ãªã„ã€‚
        """
    else:
        prompt = f"""
        ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä»Šæ—¥æˆã—é‚ã’ãŸã€Œæœ€ã‚‚é‡è¦ãªæˆæœã€ã‚’3ã¤ä»¥å†…ã§æŠ½å‡ºã—ã¦ã€‚
        ãƒ†ã‚­ã‚¹ãƒˆ: {state['today_text']}
        """

    response = llm.invoke([SystemMessage(content=CORE_PERSONA), HumanMessage(content=prompt)])
    return {"analysis_summary": response.content}

def praiser_node(state: AgentState):
    print_phase("åŠ´ã„ã¨ç§°è³› (Praiser)")
    
    prompt = f"""
    åˆ†æçµæœ: {state['analysis_summary']}
    ä¸Šè¨˜ã‚’è¸ã¾ãˆã¦ã€è¦ªå‹ã¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¤’ã‚ã¦ãã ã•ã„ã€‚
    ã€ãƒ«ãƒ¼ãƒ«ã€‘
    1. **å…¨ä½“ã§300æ–‡å­—ä»¥å†…ï¼ˆèª­ã¿ä¸Šã’ã¦1åˆ†ç¨‹åº¦ï¼‰**ã€‚
    2. åˆ†æã•ã‚ŒãŸã€Œãƒˆãƒƒãƒ—ã®æˆæœã€ã«çµã£ã¦ã€æ·±ãã€æ¸©ã‹ãè¤’ã‚ã‚‹ã€‚
    3. ã‚¯ãƒã®ã¬ã„ãã‚‹ã¿ã‚‰ã—ãã€åŒ…å®¹åŠ›ã®ã‚ã‚‹è¨€è‘‰ã§ã€‚
    """
    response = llm.invoke([SystemMessage(content=CORE_PERSONA), HumanMessage(content=prompt)])
    
    voice_client.speak_async(response.content)
    
    print_guide("è¤’ã‚è¨€è‘‰ã‚’å—ã‘å–ã£ã¦ãã ã•ã„ã€‚æº€è¶³ã—ãŸã‚‰Enterã‚­ãƒ¼ã§ã€Œæ˜æ—¥ã®ä½œæˆ¦ã€ã«é€²ã¿ã¾ã™ã€‚")
    input("(Enter) >> ")
    voice_client.stop()

    return {"messages": [AIMessage(content=response.content)]}

def strategist_node(state: AgentState):
    print_phase("æ˜æ—¥ã®ä½œæˆ¦ (Strategist)")
    
    prompt = f"""
    åˆ†æçµæœ: {state['analysis_summary']}
    æ˜æ—¥ã®ãŸã‚ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¿ƒã‚’è»½ãã™ã‚‹ææ¡ˆã‚’ã—ã¦ã€‚
    ã€ãƒ«ãƒ¼ãƒ«ã€‘
    1. **150æ–‡å­—ä»¥å†…**ã€‚
    2. ã€Œæ˜æ—¥çµ¶å¯¾ã«ã‚„ã‚‹ã¹ã1ã¤ã®ã“ã¨ï¼ˆOne Thingï¼‰ã€ã‚’ææ¡ˆã™ã‚‹ã€‚
    3. ãã‚Œä»¥å¤–ã¯ã€Œæ˜æ—¥ã¯ã‚„ã‚‰ãªãã¦ã„ã„ã€ã¨æ–­è¨€ã™ã‚‹ã€‚
    4. ã€Œã˜ã‚ƒã‚ã€æ˜æ—¥ã®ä½œæˆ¦ä¼šè­°ã‚’ã—ã‚ˆã†ã‹ã€ã‹ã‚‰å§‹ã‚ã¦ã€‚
    """
    response = llm.invoke([SystemMessage(content=CORE_PERSONA), HumanMessage(content=prompt)])
    
    voice_client.speak_async(response.content)
    
    print_guide("ææ¡ˆå†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚åˆæ„ã™ã‚‹ãªã‚‰Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    input("(Enter) >> ")
    voice_client.stop()

    return {"plan_focus": response.content, "messages": [AIMessage(content=response.content)]}

def cheer_node(state: AgentState):
    print_phase("æœ€å¾Œã®ã‚¨ãƒ¼ãƒ« (Cheer)")
    
    prompt = "æœ€å¾Œã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå®‰å¿ƒã—ã¦çœ ã‚Œã‚‹ã‚ˆã†ãªã€çŸ­ãæ¸©ã‹ã„ã€ŒãŠã‚„ã™ã¿ã€ã®ã‚¨ãƒ¼ãƒ«ã‚’é€ã£ã¦ã€‚30æ–‡å­—ä»¥å†…ã§ã€ã‚¯ãƒã¡ã‚ƒã‚“ã‚‰ã—ãã€‚"
    response = llm.invoke([SystemMessage(content=CORE_PERSONA), HumanMessage(content=prompt)])
    
    voice_client.speak_async(response.content)
    time.sleep(1)
    
    print_guide("ãŠã‚„ã™ã¿ãªã•ã„ã€‚Enterã‚­ãƒ¼ã‚’æŠ¼ã™ã¨çµ‚äº†ã—ã¾ã™ã€‚")
    input("(Enter) >> ")
    voice_client.stop()
    
    return {"messages": [AIMessage(content=response.content)]}

def logger_node(state: AgentState):
    print_phase("ãƒ­ã‚°ä¿å­˜ (Logger)")
    filename = f"yell_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.txt"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("=== Midnight Partner Log ===\n")
        f.write(f"Type: {state.get('input_type')}\n")
        f.write(f"Plan: {state.get('plan_focus')}\n")
    print(f"\nâœ… ä¼šè©±ã®è¨˜éŒ²ã‚’ {filename} ã«ç½®ã„ã¦ãŠã„ãŸã‚ˆã€‚ãŠã‚„ã™ã¿ã€‚")
    return {}

# ==========================================
# Graph
# ==========================================
workflow = StateGraph(AgentState)
workflow.add_node("input", input_handler)
workflow.add_node("interviewer", interviewer_node)
workflow.add_node("analyzer", analyzer_node)
workflow.add_node("praiser", praiser_node)
workflow.add_node("strategist", strategist_node)
workflow.add_node("cheer", cheer_node)
workflow.add_node("logger", logger_node)

workflow.set_entry_point("input")
def check_source(state): return "interviewer" if state["input_type"] == "chat" else "analyzer"
workflow.add_conditional_edges("input", check_source)
workflow.add_edge("interviewer", "analyzer")
workflow.add_edge("analyzer", "praiser")
workflow.add_edge("praiser", "strategist")
workflow.add_edge("strategist", "cheer")
workflow.add_edge("cheer", "logger")
workflow.add_edge("logger", END)
app = workflow.compile()

if __name__ == "__main__":
    app.invoke({"messages": []})
